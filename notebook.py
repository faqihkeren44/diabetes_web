# -*- coding: utf-8 -*-
"""diabetes_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1harpkwm0he8YGFOroLNfbyDRKNU4pUUR

# Proyek Diabetes Prediction

* Nama: Alif Khusain Bilfaqih
* Username: akbf_apotheosis
* Email: faqihkeren44@gmail.com

## Data Loading
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

url = 'https://raw.githubusercontent.com/faqihkeren44/diabetes/refs/heads/main/diabetes_prediction_dataset.csv'
main_df = pd.read_csv(url, sep=',')
main_df.head()

main_df.info()

describe_tabel = main_df.describe()
describe_tabel

dataset_md = main_df.to_markdown()
desribe_md = describe_tabel.to_markdown()

with open('dataset_df.md', 'w') as f:
    f.write(dataset_md)

with open('desribe_df.md', 'w') as f:
    f.write(desribe_md)

"""## Exploratory Data Analysis (EDA)"""

sns.histplot(data = main_df, x = main_df['age'], hue = main_df['diabetes'], kde = True)
plt.title('Age Distribution')
plt.savefig('vis_1.png')

fig, ax = plt.subplots(2, 2, figsize=(7, 7))
sns.countplot(data = main_df, x = 'hypertension', hue = 'diabetes', ax = ax[0, 0])
sns.countplot(data = main_df, x = 'heart_disease', hue = 'diabetes', ax = ax[0, 1])
sns.countplot(data = main_df, y = 'smoking_history', hue = 'diabetes', ax = ax[1, 0])
sns.countplot(data = main_df, x = 'gender', hue = 'diabetes', ax = ax[1, 1])
plt.tight_layout()
plt.savefig('vis_2.png')
plt.show()

fig, ax = plt.subplots(1, 3, figsize=(8, 5))
sns.countplot(data = main_df, x = 'hypertension', hue = 'gender', ax = ax[0])
sns.countplot(data = main_df, x = 'heart_disease', hue = 'gender', ax = ax[1])
sns.countplot(data = main_df, y = 'smoking_history', hue = 'gender', ax = ax[2])
plt.tight_layout()
plt.savefig('vis_3.png')
plt.show()

fig, ax = plt.subplots(1, 3)
sns.boxplot(x = main_df.diabetes, y = main_df.HbA1c_level, ax = ax[0])
sns.boxplot(x = main_df.diabetes, y = main_df.blood_glucose_level, ax = ax[1])
sns.boxplot(x = main_df.diabetes, y = main_df.bmi, ax = ax[2])
plt.tight_layout()
plt.savefig('vis_4.png')
plt.show()

"""## Data Preparation"""

main_df.isnull().sum()

main_df.duplicated().sum()

main_df.drop_duplicates(inplace=True)

main_df.gender.value_counts()

main_df = main_df[main_df.gender != 'Other']
main_df['gender'].unique()

main_df['gender'] = main_df['gender'].astype('category')
main_df['gender_code'] = main_df['gender'].cat.codes

print('0 =', main_df.gender.cat.categories[0])
print('1 =', main_df.gender.cat.categories[1])

number_df = main_df.drop(['gender', 'smoking_history'], axis=1)
number_df.head()

plt.figure(figsize=(5,5))
sns.heatmap(number_df.corr(), annot=True)
plt.show

plt.savefig('heatmap_corr.png')

corr = number_df.corr()['diabetes']. drop('diabetes')
top_features = corr[abs(corr) > 0.19].sort_values(ascending=False)
top_features = list(top_features.index)
top_features

plt.figure(figsize=(10,5))
plt.bar(x=top_features, height=corr[top_features])
plt.xlabel('Features')
plt.ylabel('Correlation')
plt.title('Correlation of Features with Diabetes')
plt.tight_layout()
plt.show()

final_df = main_df[['blood_glucose_level', 'HbA1c_level', 'age', 'bmi', 'diabetes']]
final_df.head()

label = final_df[['blood_glucose_level', 'HbA1c_level', 'age', 'bmi']].values
target = final_df['diabetes'].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(label, target, test_size = 0.2)

"""## Modeling"""

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import LinearSVC,SVC
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

models={'LogisticRegression':LogisticRegression(),
        'K-Nearest Neighbors':KNeighborsClassifier(),
        'Decision Tree':DecisionTreeClassifier(),
        'Support Vector Machine(Linear Kernel)':LinearSVC(),
        'Support Vector Machine(Non-Linear Kernal)':SVC(),
        'Neural Network':MLPClassifier(),
        'Random Forest':RandomForestClassifier(),
        'Gradient Boosting':GradientBoostingClassifier()
        }

for name, model in models.items():
    print(name)
    model.fit(X_train,y_train)
    y_pred = model.predict(X_test)
    print(classification_report(y_test, y_pred))

from sklearn.model_selection import RandomizedSearchCV

# Define the parameter grid for RandomizedSearchCV
param_dist = {
    'n_estimators': np.arange(50, 251, 50),
    'learning_rate': np.linspace(0.01, 0.2, 10),
    'max_depth': np.arange(3, 8),
}

# Initialize the Gradient Boosting model
gb_model = GradientBoostingClassifier()

# Initialize RandomizedSearchCV
random_search = RandomizedSearchCV(estimator=gb_model, param_distributions=param_dist, n_iter=10,
                                   cv=5, scoring='accuracy', random_state=42, n_jobs=-1)

# Fit the model to the training data using RandomizedSearchCV
random_search.fit(X_train, y_train)

# Get the best parameters and best model
best_params_random = random_search.best_params_
best_model_random = random_search.best_estimator_

# Make predictions on the test set using the best model
y_pred_best_random = best_model_random.predict(X_test)

# Evaluate the best model
accuracy_best_random = accuracy_score(y_test, y_pred_best_random)

"""## Akurasi"""

# Print the results
print("Best Parameters (Randomized Search):", best_params_random)
print(f"Best Model Accuracy (Randomized Search): {accuracy_best_random}")

model_report = classification_report(y_test, y_pred_best_random)
print(model_report)

with open('model_report.md', 'w') as f:
    f.write(model_report)

fig, ax = plt.subplots(figsize=(5, 5))
sns.heatmap(confusion_matrix(y_test, y_pred_best_random), annot=True, fmt=".0f", ax=ax)
plt.xlabel("y_head")
plt.ylabel("y_true")
plt.savefig('confusion_matrix.png')
plt.show()

import pickle
pickle.dump(best_model_random, open('model.pkl', 'wb'))